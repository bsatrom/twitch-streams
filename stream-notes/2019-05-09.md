# May 09, 2019 Stream

- Time: 2-4 pm Central
- VOD [https://www.twitch.tv/videos/422595599](https://www.twitch.tv/videos/422595599)

## What we did

### Show and Tell (15 minutes)

- [X] MOAR AliExpress hardware for the PortaPi Pentester!
- [X] Adafruit buttons and switches!
- [X] [Microsoft BUILD Announcements](https://azure.microsoft.com/en-us/blog/build-with-azure-iot-central-and-iot-plug-and-play/) (Iot Central, IoT Plug and Play)
- [X] Streaming schedule change!

### Edge ML & IoT Project

- [X] NEW Project: Emotion Mesh! Using the Google Coral and Particle Mesh to do Edge-based face-tracking and emotion detection
- [-] Configure VSCode's new Remote Dev for SSH on the Google Coral Board
  - Using SSH FS instead as VS Code remote doesn't support ARM-yet (Link to GH issues)
- [X] Walk through the Coral Object Detection and face-tracking source code
- [ ] Create a UART Connection between an Argon and the Coral to start the FT demo (Mesh.sub on Argon, Serial1 to Coral; Coral receives serial, triggers demo; Demo result sent back to Argon over Serial)
  --> Resource: [Coral docs](https://coral.withgoogle.com/docs/dev-board/gpio/)
- [ ] Set-up a project in Azure IoT Central for Emotion Mesh

## What we learned / Ideas for next time

- [ ] Use the medium arcade button, maybe? [@dot_commie and @phrakberg votes for the large button]
- [ ] Grokking Deep Learning is an awesome book, and there's a [GitHub site for it](https://github.com/iamtrask/Grokking-Deep-Learning)!
- [ ] We should be able to use the existing FT source and just capture an image from the webcam to use as the input; This can be extended to use emotion detection inference later
- [ ] Brandon needs to catch up on the [Tesla Autonomy Day demos](https://www.youtube.com/watch?v=-b041NXGPZ8)

Next Time! (Monday, May 13th)
- Finish UART Setup
- Set-up Webcam and image capture
- Run FT demo on a captured image